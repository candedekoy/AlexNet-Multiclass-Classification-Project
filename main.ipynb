{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "iMkl-wIyN0ox"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import shutil\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import math\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oF7lQgPuaHIV",
        "outputId": "72d1f32e-75bf-45ee-852f-83a0c0b90195"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/MyDrive\n"
          ]
        }
      ],
      "source": [
        "#If you are using google colab, mount your google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/MyDrive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Mfvp4U4INhOR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KspDhRWNOBlT",
        "outputId": "a27e64b3-3c24-44a7-a61a-18ae1d3f4738"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLkowcmeNosA",
        "outputId": "1299f13a-051a-4be1-ebb6-32768916645e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:01<00:00, 130MB/s]\n"
          ]
        }
      ],
      "source": [
        "model_conv = models.alexnet(pretrained = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZDwbi7mfOPt9"
      },
      "outputs": [],
      "source": [
        "for param in model_conv.parameters():\n",
        "  param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3QTQOrsuSXkf",
        "outputId": "b6d03ed0-befc-4809-e05a-b88f499fd002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_conv)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9ICAWbeTTPGL"
      },
      "outputs": [],
      "source": [
        "num_classes = 3\n",
        "model_conv.classifier[6] = nn.Linear(in_features=4096, out_features=num_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QgloC6kjT6Zy",
        "outputId": "be32097b-80ca-4371-e1ce-78274eb66a87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AlexNet(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (4): ReLU(inplace=True)\n",
            "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Linear(in_features=4096, out_features=3, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model_conv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Uo2lHC5mT8Mb"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model_conv.classifier.parameters(), lr=0.01)\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "S0mpfnhwNCYu"
      },
      "outputs": [],
      "source": [
        "def train_model(dataloaders, model, criterion, optimizer, scheduler, num_epochs, device):\n",
        "    model.to(device)\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs} started\")\n",
        "\n",
        "        # Training phase\n",
        "        model.train()\n",
        "        train_labels_all = []\n",
        "        train_preds_all = []\n",
        "        train_loss = 0.0\n",
        "        for inputs, labels in dataloaders['train']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            with torch.set_grad_enabled(True):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * inputs.size(0)\n",
        "            train_labels_all.extend(labels.cpu().numpy())\n",
        "            train_preds_all.extend(preds.cpu().numpy())\n",
        "\n",
        "        train_loss /= len(dataloaders['train'].dataset)\n",
        "        print(f\"Training Loss: {train_loss:.4f}\")\n",
        "\n",
        "        # Print training confusion matrix and classification report\n",
        "        print(\"Training - Confusion Matrix and Classification Report\")\n",
        "        print(confusion_matrix(train_labels_all, train_preds_all))\n",
        "        print(classification_report(train_labels_all, train_preds_all))\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        valid_labels_all = []\n",
        "        valid_preds_all = []\n",
        "        valid_loss = 0.0\n",
        "        for inputs, labels in dataloaders['valid']:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            with torch.set_grad_enabled(False):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "            valid_loss += loss.item() * inputs.size(0)\n",
        "            valid_labels_all.extend(labels.cpu().numpy())\n",
        "            valid_preds_all.extend(preds.cpu().numpy())\n",
        "\n",
        "        valid_loss /= len(dataloaders['valid'].dataset)\n",
        "        valid_acc = (np.array(valid_labels_all) == np.array(valid_preds_all)).mean()\n",
        "        print(f\"Validation Loss: {valid_loss:.4f}, Validation Accuracy: {valid_acc:.4f}\")\n",
        "\n",
        "        # Print validation confusion matrix and classification report\n",
        "        print(\"Validation - Confusion Matrix and Classification Report\")\n",
        "        print(confusion_matrix(valid_labels_all, valid_preds_all))\n",
        "        print(classification_report(valid_labels_all, valid_preds_all))\n",
        "\n",
        "        # Check if this is the best model so far\n",
        "        if valid_acc > best_acc:\n",
        "            best_acc = valid_acc\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step()\n",
        "\n",
        "    # Load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#File manipulation to create the dataset\n",
        "\n",
        "\n",
        "DATA_DIR = \"\" # Path to the dataset\n",
        "TARGET_DIR = \"\" # Path to the processed dataset\n",
        "\n",
        "TRAIN_DIR = f\"{DATA_DIR}/training\"\n",
        "TRAIN_LABELS_PATH = f\"{DATA_DIR}/training_labels.txt\"\n",
        "TEST_DIR = f\"{DATA_DIR}/test\"\n",
        "TEST_LABELS_PATH = f\"{DATA_DIR}/test_labels.txt\"\n",
        "\n",
        "VALID_SPLIT = 0.2\n",
        "\n",
        "shutil.rmtree(TARGET_DIR, ignore_errors=True)\n",
        "\n",
        "with open(TRAIN_LABELS_PATH) as f:\n",
        "    train_labels = f.read().splitlines()\n",
        "\n",
        "with open(TEST_LABELS_PATH) as f:\n",
        "    test_labels = f.read().splitlines()\n",
        "\n",
        "for label in set(train_labels):\n",
        "    os.makedirs(f\"{TARGET_DIR}/train/class-{label}\", exist_ok=True)\n",
        "    os.makedirs(f\"{TARGET_DIR}/valid/class-{label}\", exist_ok=True)\n",
        "    os.makedirs(f\"{TARGET_DIR}/test/class-{label}\", exist_ok=True)\n",
        "\n",
        "train_data = [(idx + 1, label) for idx, label in enumerate(train_labels)]\n",
        "test_data = [(idx + 1, label) for idx, label in enumerate(test_labels)]\n",
        "\n",
        "random.shuffle(train_data)\n",
        "\n",
        "num_val_items = int(len(train_data) * VALID_SPLIT)\n",
        "\n",
        "for idx, label in train_data[:num_val_items]:\n",
        "    file_path = f\"{TARGET_DIR}/valid/class-{label}/img{idx}.jpg\"\n",
        "    shutil.copyfile(f\"{TRAIN_DIR}/tr{idx}.jpg\", file_path)\n",
        "\n",
        "for idx, label in train_data[num_val_items:]:\n",
        "    file_path = f\"{TARGET_DIR}/train/class-{label}/img{idx}.jpg\"\n",
        "    shutil.copyfile(f\"{TRAIN_DIR}/tr{idx}.jpg\", file_path)\n",
        "\n",
        "for idx, label in test_data:\n",
        "    file_path = f\"{TARGET_DIR}/test/class-{label}/img{idx}.jpg\"\n",
        "    shutil.copyfile(f\"{TEST_DIR}/ts{idx}.jpg\", file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtK9YziKtTvQ",
        "outputId": "a8ccadb0-13c2-441f-9a34-853b46a8850f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculated mean: [0.7017949 0.6766075 0.7341904]\n",
            "Calculated std: [0.13982332 0.16244218 0.10425418]\n"
          ]
        }
      ],
      "source": [
        "def calculate_mean_std(data_dir, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.ImageFolder(data_dir, transform=transform)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    mean = 0.\n",
        "    std = 0.\n",
        "    nb_samples = 0.\n",
        "\n",
        "    for data, _ in loader:\n",
        "        batch_samples = data.size(0)\n",
        "        data = data.view(batch_samples, data.size(1), -1)\n",
        "        mean += data.mean(2).sum(0)\n",
        "        std += data.std(2).sum(0)\n",
        "        nb_samples += batch_samples\n",
        "\n",
        "    mean /= nb_samples\n",
        "    std /= nb_samples\n",
        "\n",
        "    return mean.numpy(), std.numpy()\n",
        "\n",
        "data = f'{TARGET_DIR}/train'\n",
        "mean, std = calculate_mean_std(data)\n",
        "print(f\"Calculated mean: {mean}\")\n",
        "print(f\"Calculated std: {std}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "vMDAI3YjBtYa"
      },
      "outputs": [],
      "source": [
        "#Data augmentation with normalization\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "}\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(TARGET_DIR, x), data_transforms[x])\n",
        "                  for x in ['train', 'valid', 'test']}\n",
        "\n",
        "\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],\n",
        "  batch_size = 4, shuffle = True)\n",
        "  for x in ['train', 'valid']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOrNv3Ymj8fB",
        "outputId": "65e116b3-02ce-4cdc-909a-e4048298f4ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train image sizes: torch.Size([4, 3, 227, 227])\n",
            "valid image sizes: torch.Size([4, 3, 227, 227])\n"
          ]
        }
      ],
      "source": [
        "def print_image_sizes(dataloaders):\n",
        "    for phase, dataloader in dataloaders.items():\n",
        "        images, _ = next(iter(dataloader))\n",
        "        print(f\"{phase} image sizes: {images.shape}\")\n",
        "print_image_sizes(dataloaders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "23e19126f07f4c8ba7be83c6caffbf7f",
            "0884c8fee97d447986b73d226ad41b95",
            "e886bc81a20142e98f587149b080a570",
            "329912544c2e44ac8bd1e33ae96f378d",
            "ee4f771edf86435b8e92baeb86d34c49",
            "8647cae95abb4122804105f062a4a49c",
            "680d1126e9874d45a60fa23f0faaf98c",
            "34501657f00347f884978e4b7a86b441",
            "c0dde37045864bf39e0f39a6239d7df3",
            "8beb4643b69744f3a6c9681f73bfb362",
            "fc872f2a453746e99a94310c24dc3089"
          ]
        },
        "id": "1zOex5zECLKP",
        "outputId": "a58c0f39-0c3c-43f1-ffb9-1aae23b75cae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23e19126f07f4c8ba7be83c6caffbf7f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 started\n",
            "Training Loss: 1.1094\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[39  8  4]\n",
            " [ 4 54  7]\n",
            " [ 8  5 20]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.76      0.76        51\n",
            "           1       0.81      0.83      0.82        65\n",
            "           2       0.65      0.61      0.62        33\n",
            "\n",
            "    accuracy                           0.76       149\n",
            "   macro avg       0.74      0.73      0.74       149\n",
            "weighted avg       0.76      0.76      0.76       149\n",
            "\n",
            "Validation Loss: 1.9322, Validation Accuracy: 0.8378\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[ 8  0  1]\n",
            " [ 3 18  2]\n",
            " [ 0  0  5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.89      0.80         9\n",
            "           1       1.00      0.78      0.88        23\n",
            "           2       0.62      1.00      0.77         5\n",
            "\n",
            "    accuracy                           0.84        37\n",
            "   macro avg       0.78      0.89      0.82        37\n",
            "weighted avg       0.88      0.84      0.84        37\n",
            "\n",
            "Epoch 2/5 started\n",
            "Training Loss: 0.6893\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[47  1  3]\n",
            " [ 3 59  3]\n",
            " [ 1  3 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92        51\n",
            "           1       0.94      0.91      0.92        65\n",
            "           2       0.83      0.88      0.85        33\n",
            "\n",
            "    accuracy                           0.91       149\n",
            "   macro avg       0.90      0.90      0.90       149\n",
            "weighted avg       0.91      0.91      0.91       149\n",
            "\n",
            "Validation Loss: 0.9558, Validation Accuracy: 0.8649\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[ 8  0  1]\n",
            " [ 1 19  3]\n",
            " [ 0  0  5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89         9\n",
            "           1       1.00      0.83      0.90        23\n",
            "           2       0.56      1.00      0.71         5\n",
            "\n",
            "    accuracy                           0.86        37\n",
            "   macro avg       0.81      0.90      0.84        37\n",
            "weighted avg       0.91      0.86      0.88        37\n",
            "\n",
            "Epoch 3/5 started\n",
            "Training Loss: 0.3708\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[49  2  0]\n",
            " [ 1 60  4]\n",
            " [ 0  2 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97        51\n",
            "           1       0.94      0.92      0.93        65\n",
            "           2       0.89      0.94      0.91        33\n",
            "\n",
            "    accuracy                           0.94       149\n",
            "   macro avg       0.93      0.94      0.94       149\n",
            "weighted avg       0.94      0.94      0.94       149\n",
            "\n",
            "Validation Loss: 1.0302, Validation Accuracy: 0.9189\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[ 9  0  0]\n",
            " [ 1 20  2]\n",
            " [ 0  0  5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95         9\n",
            "           1       1.00      0.87      0.93        23\n",
            "           2       0.71      1.00      0.83         5\n",
            "\n",
            "    accuracy                           0.92        37\n",
            "   macro avg       0.87      0.96      0.90        37\n",
            "weighted avg       0.94      0.92      0.92        37\n",
            "\n",
            "Epoch 4/5 started\n",
            "Training Loss: 0.1286\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[51  0  0]\n",
            " [ 0 64  1]\n",
            " [ 1  3 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99        51\n",
            "           1       0.96      0.98      0.97        65\n",
            "           2       0.97      0.88      0.92        33\n",
            "\n",
            "    accuracy                           0.97       149\n",
            "   macro avg       0.97      0.95      0.96       149\n",
            "weighted avg       0.97      0.97      0.97       149\n",
            "\n",
            "Validation Loss: 1.7056, Validation Accuracy: 0.8649\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[ 8  0  1]\n",
            " [ 1 19  3]\n",
            " [ 0  0  5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.89      0.89         9\n",
            "           1       1.00      0.83      0.90        23\n",
            "           2       0.56      1.00      0.71         5\n",
            "\n",
            "    accuracy                           0.86        37\n",
            "   macro avg       0.81      0.90      0.84        37\n",
            "weighted avg       0.91      0.86      0.88        37\n",
            "\n",
            "Epoch 5/5 started\n",
            "Training Loss: 1.2656\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[48  1  2]\n",
            " [ 2 55  8]\n",
            " [ 0  4 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.94      0.95        51\n",
            "           1       0.92      0.85      0.88        65\n",
            "           2       0.74      0.88      0.81        33\n",
            "\n",
            "    accuracy                           0.89       149\n",
            "   macro avg       0.87      0.89      0.88       149\n",
            "weighted avg       0.89      0.89      0.89       149\n",
            "\n",
            "Validation Loss: 1.2954, Validation Accuracy: 0.8649\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[ 9  0  0]\n",
            " [ 1 19  3]\n",
            " [ 1  0  4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      1.00      0.90         9\n",
            "           1       1.00      0.83      0.90        23\n",
            "           2       0.57      0.80      0.67         5\n",
            "\n",
            "    accuracy                           0.86        37\n",
            "   macro avg       0.80      0.88      0.82        37\n",
            "weighted avg       0.90      0.86      0.87        37\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_model = train_model(dataloaders, model_conv, criterion, optimizer, exp_lr_scheduler, 5, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8cpFdVLYRMiw"
      },
      "outputs": [],
      "source": [
        "dataloader_test = torch.utils.data.DataLoader(image_datasets[\"test\"],\n",
        "                                                  batch_size=32,\n",
        "                                                  shuffle=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tqGjFMaC5Bq",
        "outputId": "a87ffd17-3d57-40ed-ab71-281bcf25c226"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[48  0  0]\n",
            " [ 4 51  2]\n",
            " [ 1  6 32]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      1.00      0.95        48\n",
            "           1       0.89      0.89      0.89        57\n",
            "           2       0.94      0.82      0.88        39\n",
            "\n",
            "    accuracy                           0.91       144\n",
            "   macro avg       0.91      0.91      0.91       144\n",
            "weighted avg       0.91      0.91      0.91       144\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def test_model(model, dataloader, device):\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    for inputs, labels in dataloader:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    return np.array(all_preds), np.array(all_labels)\n",
        "\n",
        "test_preds, test_labels = test_model(trained_model, dataloader_test, device)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, test_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, test_preds))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZG0gRWS4gRP",
        "outputId": "cd22d18e-0030-4ee4-efa9-5e0d6df222f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Smallest class is class-3 with 38 files.\n"
          ]
        }
      ],
      "source": [
        "# Find the smallest class in the dataset\n",
        "\n",
        "num_classes = 3\n",
        "smallest_class_size=math.inf\n",
        "smallest_class = None\n",
        "\n",
        "\n",
        "for i in range(num_classes):\n",
        "  train_path = f\"{TARGET_DIR}/train/class-{i+1}\"\n",
        "  valid_path = f\"{TARGET_DIR}/valid/class-{i+1}\"\n",
        "\n",
        "  train_file_list= os.listdir(train_path)\n",
        "  valid_file_list= os.listdir(valid_path)\n",
        "  num_files = len(train_file_list) + len(valid_file_list)\n",
        "\n",
        "  if num_files < smallest_class_size:\n",
        "      smallest_class_size = num_files\n",
        "      smallest_class = i+1\n",
        "\n",
        "\n",
        "print(f\"Smallest class is class-{smallest_class} with {smallest_class_size} files.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VnxeTOBN7EP6"
      },
      "outputs": [],
      "source": [
        "#Undersample the dataset\n",
        "\n",
        "PROCESSED_DIR =\"\"# Path to the processed dataset\n",
        "BALANCED_DIR = \"\" # Path to the balanced dataset\n",
        "\n",
        "valid_split = 0.2\n",
        "\n",
        "\n",
        "os.makedirs(BALANCED_DIR, exist_ok=True)\n",
        "for i in range(1, num_classes + 1):\n",
        "    os.makedirs(f\"{BALANCED_DIR}/train/class-{i}\", exist_ok=True)\n",
        "    os.makedirs(f\"{BALANCED_DIR}/valid/class-{i}\", exist_ok=True)\n",
        "    os.makedirs(f\"{BALANCED_DIR}/test/class-{i}\", exist_ok=True)\n",
        "\n",
        "for i in range(1, num_classes + 1):\n",
        "\n",
        "    train_path = f\"{PROCESSED_DIR}/train/class-{i}\"\n",
        "    valid_path = f\"{PROCESSED_DIR}/valid/class-{i}\"\n",
        "    test_path = f\"{PROCESSED_DIR}/test/class-{i}\"\n",
        "\n",
        "    target_train_path = f\"{BALANCED_DIR}/train/class-{i}\"\n",
        "    target_valid_path = f\"{BALANCED_DIR}/valid/class-{i}\"\n",
        "    target_test_path = f\"{BALANCED_DIR}/test/class-{i}\"\n",
        "\n",
        "\n",
        "    train_file_list = os.listdir(train_path)\n",
        "    valid_file_list = os.listdir(valid_path)\n",
        "    test_file_list = os.listdir(test_path)\n",
        "\n",
        "    random.shuffle(train_file_list)\n",
        "    random.shuffle(valid_file_list)\n",
        "\n",
        "    num_val_items = int(smallest_class_size * valid_split)\n",
        "    num_train_items = smallest_class_size - num_val_items\n",
        "\n",
        "    selected_train_images = train_file_list[:num_train_items]\n",
        "    selected_valid_images = valid_file_list[:num_val_items]\n",
        "\n",
        "    for file_name in selected_train_images:\n",
        "        shutil.copy(os.path.join(train_path, file_name), os.path.join(target_train_path, file_name))\n",
        "\n",
        "    for file_name in selected_valid_images:\n",
        "        shutil.copy(os.path.join(valid_path, file_name), os.path.join(target_valid_path, file_name))\n",
        "\n",
        "    for file_name in test_file_list:\n",
        "        shutil.copy(os.path.join(test_path, file_name), os.path.join(target_test_path, file_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "FHTaJM84hR3N"
      },
      "outputs": [],
      "source": [
        "#Data augmentation and transformation with normalization and undersampling\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227),\n",
        "        transforms.Normalize(mean, std)\n",
        "    ])\n",
        "}\n",
        "\n",
        "image_datasets_norm_samp = {x: datasets.ImageFolder(os.path.join(BALANCED_DIR, x), data_transforms[x])\n",
        "                  for x in ['train', 'valid', 'test']}\n",
        "\n",
        "\n",
        "dataloaders_norm_samp = {x: torch.utils.data.DataLoader(image_datasets_norm_samp[x],\n",
        "  batch_size = 4, shuffle = True)\n",
        "  for x in ['train', 'valid']}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bdbe07688f6a48a7830fbd26b2aceae0",
            "7cc91f8ae1974e3fa3b2b6b2afa8be72",
            "f681e520d1a940838098a4557e3af1cf",
            "a511a64d5b364156b9b3e7d4fdb30285",
            "646ef9becda442cbad234bb8221f690a",
            "ed435bba5fcb4060a8e3eba122ee059b",
            "4ae67ecb97de49af8447925b39d1e699",
            "bae5ccc274254f379b3cd16116c8c0b9",
            "45fa39cdacf54f79b59ed7b93bd75c4d",
            "8e37557919dc41788b37576bf698fb20",
            "72793c5836964763a5ede2ec65f0e95e"
          ]
        },
        "id": "asBpUexphR1E",
        "outputId": "bc90dfd7-eeba-47bc-8d97-22ff461f62b8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bdbe07688f6a48a7830fbd26b2aceae0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 started\n",
            "Training Loss: 0.1142\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[29  1  1]\n",
            " [ 0 31  0]\n",
            " [ 0  2 29]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        31\n",
            "           1       0.91      1.00      0.95        31\n",
            "           2       0.97      0.94      0.95        31\n",
            "\n",
            "    accuracy                           0.96        93\n",
            "   macro avg       0.96      0.96      0.96        93\n",
            "weighted avg       0.96      0.96      0.96        93\n",
            "\n",
            "Validation Loss: 0.7006, Validation Accuracy: 0.8947\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[6 0 1]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       1.00      0.86      0.92         7\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.89        19\n",
            "   macro avg       0.90      0.90      0.90        19\n",
            "weighted avg       0.90      0.89      0.90        19\n",
            "\n",
            "Epoch 2/5 started\n",
            "Training Loss: 0.0005\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[31  0  0]\n",
            " [ 0 31  0]\n",
            " [ 0  0 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        31\n",
            "           1       1.00      1.00      1.00        31\n",
            "           2       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00        93\n",
            "   macro avg       1.00      1.00      1.00        93\n",
            "weighted avg       1.00      1.00      1.00        93\n",
            "\n",
            "Validation Loss: 0.6804, Validation Accuracy: 0.8947\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[6 1 0]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       0.86      0.86      0.86         7\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.89        19\n",
            "   macro avg       0.90      0.90      0.90        19\n",
            "weighted avg       0.89      0.89      0.89        19\n",
            "\n",
            "Epoch 3/5 started\n",
            "Training Loss: 0.0033\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[31  0  0]\n",
            " [ 0 31  0]\n",
            " [ 0  0 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        31\n",
            "           1       1.00      1.00      1.00        31\n",
            "           2       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00        93\n",
            "   macro avg       1.00      1.00      1.00        93\n",
            "weighted avg       1.00      1.00      1.00        93\n",
            "\n",
            "Validation Loss: 0.6851, Validation Accuracy: 0.8947\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[6 0 1]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       1.00      0.86      0.92         7\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.89        19\n",
            "   macro avg       0.90      0.90      0.90        19\n",
            "weighted avg       0.90      0.89      0.90        19\n",
            "\n",
            "Epoch 4/5 started\n",
            "Training Loss: 0.0037\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[31  0  0]\n",
            " [ 0 31  0]\n",
            " [ 0  0 31]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        31\n",
            "           1       1.00      1.00      1.00        31\n",
            "           2       1.00      1.00      1.00        31\n",
            "\n",
            "    accuracy                           1.00        93\n",
            "   macro avg       1.00      1.00      1.00        93\n",
            "weighted avg       1.00      1.00      1.00        93\n",
            "\n",
            "Validation Loss: 0.7004, Validation Accuracy: 0.8947\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[6 0 1]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       1.00      0.86      0.92         7\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.89        19\n",
            "   macro avg       0.90      0.90      0.90        19\n",
            "weighted avg       0.90      0.89      0.90        19\n",
            "\n",
            "Epoch 5/5 started\n",
            "Training Loss: 0.0759\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[31  0  0]\n",
            " [ 0 31  0]\n",
            " [ 0  1 30]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        31\n",
            "           1       0.97      1.00      0.98        31\n",
            "           2       1.00      0.97      0.98        31\n",
            "\n",
            "    accuracy                           0.99        93\n",
            "   macro avg       0.99      0.99      0.99        93\n",
            "weighted avg       0.99      0.99      0.99        93\n",
            "\n",
            "Validation Loss: 0.7036, Validation Accuracy: 0.8947\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[6 0 1]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86         7\n",
            "           1       1.00      0.86      0.92         7\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.89        19\n",
            "   macro avg       0.90      0.90      0.90        19\n",
            "weighted avg       0.90      0.89      0.90        19\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_model_norm_under_sampled = train_model(dataloaders_norm_samp, model_conv, criterion, optimizer, exp_lr_scheduler, 5, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "XOzf2-ORhRyc"
      },
      "outputs": [],
      "source": [
        "dataloader_test_norm_samp = torch.utils.data.DataLoader(image_datasets_norm_samp[\"test\"],\n",
        "                                                  batch_size=32,\n",
        "                                                  shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxVabFxKhrOn",
        "outputId": "f8e19bbf-4185-40cd-ceea-a52701ae6a0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[48  0  0]\n",
            " [ 2 54  1]\n",
            " [ 0  6 33]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        48\n",
            "           1       0.90      0.95      0.92        57\n",
            "           2       0.97      0.85      0.90        39\n",
            "\n",
            "    accuracy                           0.94       144\n",
            "   macro avg       0.94      0.93      0.94       144\n",
            "weighted avg       0.94      0.94      0.94       144\n",
            "\n"
          ]
        }
      ],
      "source": [
        "test_preds, test_labels = test_model(trained_model_norm_under_sampled, dataloader_test_norm_samp, device)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, test_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, test_preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jE9DqgfieTu8"
      },
      "outputs": [],
      "source": [
        "#Data augmentation and transformation with undersampling and no normalization\n",
        "\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227)\n",
        "    ]),\n",
        "    'valid': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227)\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize(227)\n",
        "    ])\n",
        "}\n",
        "\n",
        "image_datasets_undersampled = {x: datasets.ImageFolder(os.path.join(BALANCED_DIR, x), data_transforms[x])\n",
        "                  for x in ['train', 'valid', 'test']}\n",
        "\n",
        "\n",
        "dataloaders_undersampled = {x: torch.utils.data.DataLoader(image_datasets_undersampled[x],\n",
        "  batch_size = 4, shuffle = True)\n",
        "  for x in ['train', 'valid']}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b939b6d706324a87b7108470ae38b707",
            "eb952ce90a6a4b4796e6e1b544e2e013",
            "7a5af5b4d9b249f2afb66730d7f25559",
            "021b71fb9dc349229d70d4302b9c0a6b",
            "605842cce7d143298d4c080b8df736cb",
            "4e59e0fb6574456dafcf7eda44360a94",
            "53c6b559fa054175a492b82bb7402bed",
            "a464b7e2aecd479e91a69024584c5bbf",
            "57c729d98ad644bda07887dbb8eb9671",
            "5e509908ffb64a649d78d5c7118570bc",
            "a7cbfbaf26914a0697524ef44d13fef8"
          ]
        },
        "id": "ND6siJYZg4BT",
        "outputId": "b2bac052-b7a0-4e5e-eec7-8ae65e421d35"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b939b6d706324a87b7108470ae38b707",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5 started\n",
            "Training Loss: 1.0964\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[23  7  1]\n",
            " [ 2 28  1]\n",
            " [ 0  6 25]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.74      0.82        31\n",
            "           1       0.68      0.90      0.78        31\n",
            "           2       0.93      0.81      0.86        31\n",
            "\n",
            "    accuracy                           0.82        93\n",
            "   macro avg       0.84      0.82      0.82        93\n",
            "weighted avg       0.84      0.82      0.82        93\n",
            "\n",
            "Validation Loss: 1.3588, Validation Accuracy: 0.8421\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[5 2 0]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77         7\n",
            "           1       0.75      0.86      0.80         7\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.84        19\n",
            "   macro avg       0.86      0.86      0.86        19\n",
            "weighted avg       0.85      0.84      0.84        19\n",
            "\n",
            "Epoch 2/5 started\n",
            "Training Loss: 0.5566\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[27  4  0]\n",
            " [ 2 26  3]\n",
            " [ 2  1 28]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.87      0.87        31\n",
            "           1       0.84      0.84      0.84        31\n",
            "           2       0.90      0.90      0.90        31\n",
            "\n",
            "    accuracy                           0.87        93\n",
            "   macro avg       0.87      0.87      0.87        93\n",
            "weighted avg       0.87      0.87      0.87        93\n",
            "\n",
            "Validation Loss: 1.3578, Validation Accuracy: 0.8421\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[5 2 0]\n",
            " [1 6 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.71      0.77         7\n",
            "           1       0.75      0.86      0.80         7\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.84        19\n",
            "   macro avg       0.86      0.86      0.86        19\n",
            "weighted avg       0.85      0.84      0.84        19\n",
            "\n",
            "Epoch 3/5 started\n",
            "Training Loss: 0.9079\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[26  5  0]\n",
            " [ 2 28  1]\n",
            " [ 0  4 27]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.84      0.88        31\n",
            "           1       0.76      0.90      0.82        31\n",
            "           2       0.96      0.87      0.92        31\n",
            "\n",
            "    accuracy                           0.87        93\n",
            "   macro avg       0.88      0.87      0.87        93\n",
            "weighted avg       0.88      0.87      0.87        93\n",
            "\n",
            "Validation Loss: 1.3545, Validation Accuracy: 0.7895\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[5 2 0]\n",
            " [2 5 0]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71         7\n",
            "           1       0.71      0.71      0.71         7\n",
            "           2       1.00      1.00      1.00         5\n",
            "\n",
            "    accuracy                           0.79        19\n",
            "   macro avg       0.81      0.81      0.81        19\n",
            "weighted avg       0.79      0.79      0.79        19\n",
            "\n",
            "Epoch 4/5 started\n",
            "Training Loss: 0.6528\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[24  6  1]\n",
            " [ 4 27  0]\n",
            " [ 1  6 24]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.77      0.80        31\n",
            "           1       0.69      0.87      0.77        31\n",
            "           2       0.96      0.77      0.86        31\n",
            "\n",
            "    accuracy                           0.81        93\n",
            "   macro avg       0.83      0.81      0.81        93\n",
            "weighted avg       0.83      0.81      0.81        93\n",
            "\n",
            "Validation Loss: 1.3519, Validation Accuracy: 0.7368\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[5 2 0]\n",
            " [2 4 1]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71         7\n",
            "           1       0.67      0.57      0.62         7\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.74        19\n",
            "   macro avg       0.74      0.76      0.75        19\n",
            "weighted avg       0.73      0.74      0.73        19\n",
            "\n",
            "Epoch 5/5 started\n",
            "Training Loss: 0.7243\n",
            "Training - Confusion Matrix and Classification Report\n",
            "[[23  7  1]\n",
            " [ 1 29  1]\n",
            " [ 0  5 26]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.74      0.84        31\n",
            "           1       0.71      0.94      0.81        31\n",
            "           2       0.93      0.84      0.88        31\n",
            "\n",
            "    accuracy                           0.84        93\n",
            "   macro avg       0.86      0.84      0.84        93\n",
            "weighted avg       0.86      0.84      0.84        93\n",
            "\n",
            "Validation Loss: 1.3502, Validation Accuracy: 0.7368\n",
            "Validation - Confusion Matrix and Classification Report\n",
            "[[5 2 0]\n",
            " [2 4 1]\n",
            " [0 0 5]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.71      0.71         7\n",
            "           1       0.67      0.57      0.62         7\n",
            "           2       0.83      1.00      0.91         5\n",
            "\n",
            "    accuracy                           0.74        19\n",
            "   macro avg       0.74      0.76      0.75        19\n",
            "weighted avg       0.73      0.74      0.73        19\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trained_model_undersamp = train_model(dataloaders_undersampled, model_conv, criterion, optimizer, exp_lr_scheduler, 5, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LgymyOGog8FT",
        "outputId": "1d346210-8082-4aa9-8d2d-59a25d02de6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix:\n",
            "[[36  8  4]\n",
            " [ 3 46  8]\n",
            " [ 0  5 34]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.75      0.83        48\n",
            "           1       0.78      0.81      0.79        57\n",
            "           2       0.74      0.87      0.80        39\n",
            "\n",
            "    accuracy                           0.81       144\n",
            "   macro avg       0.81      0.81      0.81       144\n",
            "weighted avg       0.82      0.81      0.81       144\n",
            "\n"
          ]
        }
      ],
      "source": [
        "dataloader_test_undersampled = torch.utils.data.DataLoader(image_datasets_undersampled[\"test\"],\n",
        "                                                  batch_size=32,\n",
        "                                                  shuffle=True)\n",
        "\n",
        "test_preds, test_labels = test_model(trained_model_undersamp, dataloader_test_undersampled, device)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(confusion_matrix(test_labels, test_preds))\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_labels, test_preds))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "021b71fb9dc349229d70d4302b9c0a6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e509908ffb64a649d78d5c7118570bc",
            "placeholder": "​",
            "style": "IPY_MODEL_a7cbfbaf26914a0697524ef44d13fef8",
            "value": " 5/5 [00:03&lt;00:00,  1.26it/s]"
          }
        },
        "0884c8fee97d447986b73d226ad41b95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8647cae95abb4122804105f062a4a49c",
            "placeholder": "​",
            "style": "IPY_MODEL_680d1126e9874d45a60fa23f0faaf98c",
            "value": "100%"
          }
        },
        "23e19126f07f4c8ba7be83c6caffbf7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0884c8fee97d447986b73d226ad41b95",
              "IPY_MODEL_e886bc81a20142e98f587149b080a570",
              "IPY_MODEL_329912544c2e44ac8bd1e33ae96f378d"
            ],
            "layout": "IPY_MODEL_ee4f771edf86435b8e92baeb86d34c49"
          }
        },
        "329912544c2e44ac8bd1e33ae96f378d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8beb4643b69744f3a6c9681f73bfb362",
            "placeholder": "​",
            "style": "IPY_MODEL_fc872f2a453746e99a94310c24dc3089",
            "value": " 5/5 [00:08&lt;00:00,  1.44s/it]"
          }
        },
        "34501657f00347f884978e4b7a86b441": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45fa39cdacf54f79b59ed7b93bd75c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ae67ecb97de49af8447925b39d1e699": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4e59e0fb6574456dafcf7eda44360a94": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53c6b559fa054175a492b82bb7402bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57c729d98ad644bda07887dbb8eb9671": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e509908ffb64a649d78d5c7118570bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "605842cce7d143298d4c080b8df736cb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "646ef9becda442cbad234bb8221f690a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "680d1126e9874d45a60fa23f0faaf98c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72793c5836964763a5ede2ec65f0e95e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a5af5b4d9b249f2afb66730d7f25559": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a464b7e2aecd479e91a69024584c5bbf",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_57c729d98ad644bda07887dbb8eb9671",
            "value": 5
          }
        },
        "7cc91f8ae1974e3fa3b2b6b2afa8be72": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed435bba5fcb4060a8e3eba122ee059b",
            "placeholder": "​",
            "style": "IPY_MODEL_4ae67ecb97de49af8447925b39d1e699",
            "value": "100%"
          }
        },
        "8647cae95abb4122804105f062a4a49c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8beb4643b69744f3a6c9681f73bfb362": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e37557919dc41788b37576bf698fb20": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a464b7e2aecd479e91a69024584c5bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a511a64d5b364156b9b3e7d4fdb30285": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e37557919dc41788b37576bf698fb20",
            "placeholder": "​",
            "style": "IPY_MODEL_72793c5836964763a5ede2ec65f0e95e",
            "value": " 5/5 [00:03&lt;00:00,  1.32it/s]"
          }
        },
        "a7cbfbaf26914a0697524ef44d13fef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b939b6d706324a87b7108470ae38b707": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb952ce90a6a4b4796e6e1b544e2e013",
              "IPY_MODEL_7a5af5b4d9b249f2afb66730d7f25559",
              "IPY_MODEL_021b71fb9dc349229d70d4302b9c0a6b"
            ],
            "layout": "IPY_MODEL_605842cce7d143298d4c080b8df736cb"
          }
        },
        "bae5ccc274254f379b3cd16116c8c0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdbe07688f6a48a7830fbd26b2aceae0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cc91f8ae1974e3fa3b2b6b2afa8be72",
              "IPY_MODEL_f681e520d1a940838098a4557e3af1cf",
              "IPY_MODEL_a511a64d5b364156b9b3e7d4fdb30285"
            ],
            "layout": "IPY_MODEL_646ef9becda442cbad234bb8221f690a"
          }
        },
        "c0dde37045864bf39e0f39a6239d7df3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e886bc81a20142e98f587149b080a570": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34501657f00347f884978e4b7a86b441",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0dde37045864bf39e0f39a6239d7df3",
            "value": 5
          }
        },
        "eb952ce90a6a4b4796e6e1b544e2e013": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e59e0fb6574456dafcf7eda44360a94",
            "placeholder": "​",
            "style": "IPY_MODEL_53c6b559fa054175a492b82bb7402bed",
            "value": "100%"
          }
        },
        "ed435bba5fcb4060a8e3eba122ee059b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee4f771edf86435b8e92baeb86d34c49": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f681e520d1a940838098a4557e3af1cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae5ccc274254f379b3cd16116c8c0b9",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45fa39cdacf54f79b59ed7b93bd75c4d",
            "value": 5
          }
        },
        "fc872f2a453746e99a94310c24dc3089": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
